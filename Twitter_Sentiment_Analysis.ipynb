{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAxuE9s99p8DSTsEs5DQ5G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmdang1101/twitter_sentiment_analysis/blob/main/Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries #"
      ],
      "metadata": {
        "id": "qvAywz9_By2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers module to use transformer models from HuggingFace\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFI3tLuxgrxV",
        "outputId": "043ce10f-7bff-4265-ff5a-c4fc4e2dcd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.0 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connects this notebook to Google Drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "pathname = \"/content/drive/My Drive/Twitter Sentiment Analysis/\"\n",
        "os.chdir(pathname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRQE3tyhe4XL",
        "outputId": "0cb513ae-34e1-49f7-94b7-cba78e0a8a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tweepy\n",
        "from tweepy import API \n",
        "from tweepy import OAuthHandler\n",
        " \n",
        "import twitter_credentials\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "v-HcMdq2XYYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweepy and Data Pre-Processing #"
      ],
      "metadata": {
        "id": "8reDOqqiB6w3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ55qzNWN50O"
      },
      "outputs": [],
      "source": [
        "# Twitter Authenticator #\n",
        "class TwitterAuthenticator():\n",
        "    def authenticate_twitter_app(self):\n",
        "        auth = OAuthHandler(twitter_credentials.CONSUMER_KEY, twitter_credentials.CONSUMER_SECRET)\n",
        "        auth.set_access_token(twitter_credentials.ACCESS_TOKEN, twitter_credentials.ACCESS_TOKEN_SECRET)\n",
        "        return auth\n",
        "        \n",
        "# Twitter Client #\n",
        "class TwitterClient():\n",
        "    def __init__(self, twitter_user=None):\n",
        "        self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
        "        self.twitter_client = API(self.auth)\n",
        "        self.twitter_user = twitter_user\n",
        "\n",
        "    def get_twitter_client_api(self):\n",
        "        return self.twitter_client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet Analyzer #\n",
        "class TweetAnalyzer():\n",
        "    def clean_tweet(self, tweet):\n",
        "        return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', tweet).split())\n",
        "\n",
        "    def tweets_to_data_frame(self, tweets):\n",
        "        df = pd.DataFrame(data=[tweet.full_text for tweet in tweets], columns=['tweets'])\n",
        "\n",
        "        df['len'] = np.array([len(tweet.full_text) for tweet in tweets])\n",
        "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
        "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
        "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
        "\n",
        "        return df\n",
        "\n",
        "    def transformer_model(self, tweet):\n",
        "        # preprocess tweet\n",
        "        tweet_words = []\n",
        "\n",
        "        for word in tweet.split(' '):\n",
        "            if word.startswith('@') and len(word) > 1:\n",
        "                word = '@user'\n",
        "            \n",
        "            elif word.startswith('http'):\n",
        "                word = 'http'\n",
        "                if len(tweet_words) == 0:\n",
        "                  return 0\n",
        "            tweet_words.append(word)\n",
        "\n",
        "        processed_tweet = ' '.join(tweet_words)\n",
        "\n",
        "        # load model and tokenizer\n",
        "        model_name = 'm-newhauser/distilbert-political-tweets'\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        # sentiment analysis\n",
        "        encoded_tweet = tokenizer(processed_tweet, return_tensors='pt')\n",
        "        output = model(**encoded_tweet)\n",
        "\n",
        "        scores = output[0][0].detach().numpy()\n",
        "        scores = softmax(scores)\n",
        "\n",
        "        # tweet score\n",
        "        max = 0\n",
        "        index = 0\n",
        "        for i in range(len(scores)):\n",
        "          if max < scores[i]:\n",
        "            max = scores[i]\n",
        "            index = i\n",
        "\n",
        "        if index == 0:\n",
        "          return 1\n",
        "        else:\n",
        "          return -1"
      ],
      "metadata": {
        "id": "51tXkaJ6DyOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Political Orientation Score #"
      ],
      "metadata": {
        "id": "NLOIRWNZCHxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_user(user_handle):\n",
        "  twitter_client = TwitterClient()\n",
        "  tweet_analyzer = TweetAnalyzer()\n",
        "\n",
        "  api = twitter_client.get_twitter_client_api()\n",
        "\n",
        "  tweets = api.user_timeline(screen_name = user_handle, count = 200, include_rts = False, tweet_mode = 'extended')\n",
        "\n",
        "  df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
        "\n",
        "  with pd.option_context('expand_frame_repr', False):\n",
        "    print(df.head())\n",
        "\n",
        "  df['sentiment'] = np.array([tweet_analyzer.transformer_model(tweet) for tweet in df['tweets']])\n",
        "\n",
        "  return round(df.loc[:, 'sentiment'].mean() * 10, 2)"
      ],
      "metadata": {
        "id": "IH92C3R6xUc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_handle = input(\"Give me a Twitter user handle: \")\n",
        "score = classify_user(user_handle)\n",
        "print(f\"\\nI predict this user to have a score of {score} on the political orientation scale.\")"
      ],
      "metadata": {
        "id": "S39PLuAlDF7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3327aa7-ca62-4073-9a8e-29479b0ee5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give me a Twitter user handle: \n",
            "@forsberg370\n",
            "                                              tweets  len                date  likes  retweets\n",
            "0  Learn with me on Duolingo! I’m moving up the l...  180 2023-01-16 15:18:17      0         0\n",
            "1  Learn a language with me for free! Duolingo is...  142 2023-01-11 16:42:29      0         0\n",
            "2  Look how much I learned on Duolingo in 2022! H...   97 2022-12-07 03:16:26      0         0\n",
            "3  Look how much I learned on Duolingo in 2022! H...   97 2022-12-07 03:16:15      0         0\n",
            "4  Learn with me on Duolingo! I’m moving up the l...  180 2022-12-05 03:00:53      1         0\n",
            "\n",
            "I predict this user to have a score of 1.33 on the political orientation scale.\n"
          ]
        }
      ]
    }
  ]
}